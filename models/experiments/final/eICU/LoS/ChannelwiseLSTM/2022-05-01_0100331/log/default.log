2022-05-01 01:00:33,264 - INFO - Config:
2022-05-01 01:00:33,264 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/final/eICU/LoS/ChannelwiseLSTM",
    "batch_norm": "mybatchnorm",
    "batch_size": 256,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "bidirectional": false,
    "channelwise": true,
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "ChannelwiseLSTM",
    "hidden_size": 8,
    "intermediate_reporting": false,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00129,
    "loss": "msle",
    "lstm_dropout_rate": 0.2,
    "main_dropout_rate": 0.45,
    "mode": "train",
    "n_epochs": 30,
    "n_layers": 2,
    "name": "ChannelwiseLSTM",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "percentage_data": 100.0,
    "save_results_csv": false,
    "seed": 3782869777,
    "shuffle_train": true,
    "sum_losses": true,
    "task": "LoS"
}
2022-05-01 01:00:39,071 - INFO - Experiment set up.
2022-05-01 01:00:42,549 - INFO - BaseLSTM(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (lstm_dropout): Dropout(p=0.2, inplace=False)
  (main_dropout): Dropout(p=0.45, inplace=False)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (empty_module): EmptyModule()
  (channelwise_lstm_list): ModuleList(
    (0): LSTM(2, 8, num_layers=2, dropout=0.2)
    (1): LSTM(2, 8, num_layers=2, dropout=0.2)
    (2): LSTM(2, 8, num_layers=2, dropout=0.2)
    (3): LSTM(2, 8, num_layers=2, dropout=0.2)
    (4): LSTM(2, 8, num_layers=2, dropout=0.2)
    (5): LSTM(2, 8, num_layers=2, dropout=0.2)
    (6): LSTM(2, 8, num_layers=2, dropout=0.2)
    (7): LSTM(2, 8, num_layers=2, dropout=0.2)
    (8): LSTM(2, 8, num_layers=2, dropout=0.2)
    (9): LSTM(2, 8, num_layers=2, dropout=0.2)
    (10): LSTM(2, 8, num_layers=2, dropout=0.2)
    (11): LSTM(2, 8, num_layers=2, dropout=0.2)
    (12): LSTM(2, 8, num_layers=2, dropout=0.2)
    (13): LSTM(2, 8, num_layers=2, dropout=0.2)
    (14): LSTM(2, 8, num_layers=2, dropout=0.2)
    (15): LSTM(2, 8, num_layers=2, dropout=0.2)
    (16): LSTM(2, 8, num_layers=2, dropout=0.2)
    (17): LSTM(2, 8, num_layers=2, dropout=0.2)
    (18): LSTM(2, 8, num_layers=2, dropout=0.2)
    (19): LSTM(2, 8, num_layers=2, dropout=0.2)
    (20): LSTM(2, 8, num_layers=2, dropout=0.2)
    (21): LSTM(2, 8, num_layers=2, dropout=0.2)
    (22): LSTM(2, 8, num_layers=2, dropout=0.2)
    (23): LSTM(2, 8, num_layers=2, dropout=0.2)
    (24): LSTM(2, 8, num_layers=2, dropout=0.2)
    (25): LSTM(2, 8, num_layers=2, dropout=0.2)
    (26): LSTM(2, 8, num_layers=2, dropout=0.2)
    (27): LSTM(2, 8, num_layers=2, dropout=0.2)
    (28): LSTM(2, 8, num_layers=2, dropout=0.2)
    (29): LSTM(2, 8, num_layers=2, dropout=0.2)
    (30): LSTM(2, 8, num_layers=2, dropout=0.2)
    (31): LSTM(2, 8, num_layers=2, dropout=0.2)
    (32): LSTM(2, 8, num_layers=2, dropout=0.2)
    (33): LSTM(2, 8, num_layers=2, dropout=0.2)
    (34): LSTM(2, 8, num_layers=2, dropout=0.2)
    (35): LSTM(2, 8, num_layers=2, dropout=0.2)
    (36): LSTM(2, 8, num_layers=2, dropout=0.2)
    (37): LSTM(2, 8, num_layers=2, dropout=0.2)
    (38): LSTM(2, 8, num_layers=2, dropout=0.2)
    (39): LSTM(2, 8, num_layers=2, dropout=0.2)
    (40): LSTM(2, 8, num_layers=2, dropout=0.2)
    (41): LSTM(2, 8, num_layers=2, dropout=0.2)
    (42): LSTM(2, 8, num_layers=2, dropout=0.2)
    (43): LSTM(2, 8, num_layers=2, dropout=0.2)
    (44): LSTM(2, 8, num_layers=2, dropout=0.2)
    (45): LSTM(2, 8, num_layers=2, dropout=0.2)
    (46): LSTM(2, 8, num_layers=2, dropout=0.2)
    (47): LSTM(2, 8, num_layers=2, dropout=0.2)
    (48): LSTM(2, 8, num_layers=2, dropout=0.2)
    (49): LSTM(2, 8, num_layers=2, dropout=0.2)
    (50): LSTM(2, 8, num_layers=2, dropout=0.2)
    (51): LSTM(2, 8, num_layers=2, dropout=0.2)
    (52): LSTM(2, 8, num_layers=2, dropout=0.2)
    (53): LSTM(2, 8, num_layers=2, dropout=0.2)
    (54): LSTM(2, 8, num_layers=2, dropout=0.2)
    (55): LSTM(2, 8, num_layers=2, dropout=0.2)
    (56): LSTM(2, 8, num_layers=2, dropout=0.2)
    (57): LSTM(2, 8, num_layers=2, dropout=0.2)
    (58): LSTM(2, 8, num_layers=2, dropout=0.2)
    (59): LSTM(2, 8, num_layers=2, dropout=0.2)
    (60): LSTM(2, 8, num_layers=2, dropout=0.2)
    (61): LSTM(2, 8, num_layers=2, dropout=0.2)
    (62): LSTM(2, 8, num_layers=2, dropout=0.2)
    (63): LSTM(2, 8, num_layers=2, dropout=0.2)
    (64): LSTM(2, 8, num_layers=2, dropout=0.2)
    (65): LSTM(2, 8, num_layers=2, dropout=0.2)
    (66): LSTM(2, 8, num_layers=2, dropout=0.2)
    (67): LSTM(2, 8, num_layers=2, dropout=0.2)
    (68): LSTM(2, 8, num_layers=2, dropout=0.2)
    (69): LSTM(2, 8, num_layers=2, dropout=0.2)
    (70): LSTM(2, 8, num_layers=2, dropout=0.2)
    (71): LSTM(2, 8, num_layers=2, dropout=0.2)
    (72): LSTM(2, 8, num_layers=2, dropout=0.2)
    (73): LSTM(2, 8, num_layers=2, dropout=0.2)
    (74): LSTM(2, 8, num_layers=2, dropout=0.2)
    (75): LSTM(2, 8, num_layers=2, dropout=0.2)
    (76): LSTM(2, 8, num_layers=2, dropout=0.2)
    (77): LSTM(2, 8, num_layers=2, dropout=0.2)
    (78): LSTM(2, 8, num_layers=2, dropout=0.2)
    (79): LSTM(2, 8, num_layers=2, dropout=0.2)
    (80): LSTM(2, 8, num_layers=2, dropout=0.2)
    (81): LSTM(2, 8, num_layers=2, dropout=0.2)
    (82): LSTM(2, 8, num_layers=2, dropout=0.2)
    (83): LSTM(2, 8, num_layers=2, dropout=0.2)
    (84): LSTM(2, 8, num_layers=2, dropout=0.2)
    (85): LSTM(2, 8, num_layers=2, dropout=0.2)
    (86): LSTM(2, 8, num_layers=2, dropout=0.2)
  )
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_los): Linear(in_features=825, out_features=17, bias=True)
  (point_mort): Linear(in_features=825, out_features=17, bias=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
)
2022-05-01 01:01:12,548 - INFO - Experiment exited. Checkpoints stored =)
