2022-04-29 17:15:27,621 - INFO - Config:
2022-04-29 17:15:27,623 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/final/eICU/LoS/TPC",
    "batch_norm": "mybatchnorm",
    "batch_size": 64,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "TPC",
    "intermediate_reporting": false,
    "kernel_size": 4,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00226,
    "loss": "msle",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 2,
    "n_layers": 9,
    "name": "TPC",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "no_skip_connections": false,
    "no_temp_kernels": 12,
    "percentage_data": 100.0,
    "point_size": 13,
    "point_sizes": [
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13
    ],
    "save_results_csv": false,
    "seed": 1343203830,
    "share_weights": false,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "temp_dropout_rate": 0.05,
    "temp_kernels": [
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12
    ]
}
2022-04-29 17:15:34,704 - INFO - Experiment set up.
2022-04-29 17:15:34,727 - INFO - TempPointConv(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (main_dropout): Dropout(p=0.45, inplace=False)
  (temp_dropout): Dropout(p=0.05, inplace=False)
  (empty_module): EmptyModule()
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
  (layer_modules): ModuleDict(
    (0): ModuleDict(
      (temp): Conv1d(174, 1044, kernel_size=(4,), stride=(1,), groups=87)
      (bn_temp): MyBatchNorm1d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=241, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ModuleDict(
      (temp): Conv1d(1300, 1200, kernel_size=(4,), stride=(1,), dilation=(3,), groups=100)
      (bn_temp): MyBatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1298, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ModuleDict(
      (temp): Conv1d(1469, 1356, kernel_size=(4,), stride=(1,), dilation=(6,), groups=113)
      (bn_temp): MyBatchNorm1d(1356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1454, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ModuleDict(
      (temp): Conv1d(1638, 1512, kernel_size=(4,), stride=(1,), dilation=(9,), groups=126)
      (bn_temp): MyBatchNorm1d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1610, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ModuleDict(
      (temp): Conv1d(1807, 1668, kernel_size=(4,), stride=(1,), dilation=(12,), groups=139)
      (bn_temp): MyBatchNorm1d(1668, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1766, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): ModuleDict(
      (temp): Conv1d(1976, 1824, kernel_size=(4,), stride=(1,), dilation=(15,), groups=152)
      (bn_temp): MyBatchNorm1d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1922, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): ModuleDict(
      (temp): Conv1d(2145, 1980, kernel_size=(4,), stride=(1,), dilation=(18,), groups=165)
      (bn_temp): MyBatchNorm1d(1980, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2078, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): ModuleDict(
      (temp): Conv1d(2314, 2136, kernel_size=(4,), stride=(1,), dilation=(21,), groups=178)
      (bn_temp): MyBatchNorm1d(2136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2234, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): ModuleDict(
      (temp): Conv1d(2483, 2292, kernel_size=(4,), stride=(1,), dilation=(24,), groups=191)
      (bn_temp): MyBatchNorm1d(2292, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2390, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (point_last_los): Linear(in_features=2781, out_features=17, bias=True)
  (point_last_mort): Linear(in_features=2781, out_features=17, bias=True)
)
2022-04-29 17:17:41,564 - INFO - Custom bins confusion matrix:
2022-04-29 17:17:41,567 - INFO - [[2119 5065 1627  593  295  120   80   51  145  147]
 [1163 2795  896  304  156   91   52   38  117  128]
 [ 795 1677  535  222  123   65   50   38  107  126]
 [ 461  931  358  186   91   88   53   31   89  108]
 [ 314  696  288  154   81   56   37   23   86  101]
 [ 282  634  200  105   62   42   28   18   61   94]
 [ 220  379  135   78   60   46   28   32   71   89]
 [  69  185  115   65   62   38   36   27   79   96]
 [ 269  837  376  246  209  143   95  110  372  951]
 [ 662 1305  640  400  309  232  197  180  581 1116]]
2022-04-29 17:17:42,647 - INFO - Epoch: 0 | Train Loss: 191.3227
2022-04-29 17:18:30,571 - INFO - Custom bins confusion matrix:
2022-04-29 17:18:30,571 - INFO - [[2022 6914  752  442  228   50   62   36   70    0]
 [1104 4300  642  238   96   46   40   32   22    0]
 [ 654 2906  406  150   72   58   56   28   14    0]
 [ 356 1860  432  148   44   24   30   28   70    0]
 [ 168 1202  226  172   88   70   40   36   48    0]
 [ 106  884  296  218   56   22   34   42   36    0]
 [ 116  798  252  128   92   42   20   14    4    0]
 [  88  784  214   66   72   58   20    0    0    0]
 [ 294 2580  788  464  138   86   46   32   12    0]
 [ 148 1218  286   46   96   56   10    6    0    0]]
2022-04-29 17:18:31,231 - INFO - Epoch: 0 | Validation Loss: 156.1640
2022-04-29 17:20:24,948 - INFO - Custom bins confusion matrix:
2022-04-29 17:20:24,950 - INFO - [[3174 6298  479  144   56   44   21   10   14    2]
 [1397 3712  380  136   57   22   12    8   14    2]
 [ 757 2424  314  105   48   39   21   15   13    2]
 [ 394 1467  308   96   34   38   22    9   23    5]
 [ 247 1150  204   88   63   31   22   10   18    3]
 [ 239  862  178  113   49   34   21    9   19    2]
 [ 149  559  171   98   61   32   19   14   28    7]
 [  29  298  166   94   59   47   19   17   32   11]
 [  88  861  497  369  259  211  180  134  436  573]
 [ 115  824  538  409  305  263  205  179  756 2028]]
2022-04-29 17:20:25,720 - INFO - Epoch: 1 | Train Loss: 126.3590
2022-04-29 17:21:09,923 - INFO - Custom bins confusion matrix:
2022-04-29 17:21:09,924 - INFO - [[1868 6552 1130  416  134  148  158   84   86    0]
 [1128 3852  780  302  122  116  102   60   58    0]
 [ 428 2858  518  184  128   66   38   50   74    0]
 [ 266 1880  394  148   86   18   16   46  102   36]
 [ 108 1048  408  140   98   42   52   36   80   38]
 [ 146  716  334  164   96   38   18   34  136   12]
 [ 152  488  366  116  134  108   46   20   36    0]
 [ 104  528  314   94   66   86   58   32   20    0]
 [ 250 1680  928  702  264  106   82   70  358    0]
 [ 110 1266  168   70   94   76   50   32    0    0]]
2022-04-29 17:21:11,000 - INFO - Epoch: 1 | Validation Loss: 151.0005
2022-04-29 17:21:11,002 - INFO - Experiment ended. Checkpoints stored =)
