2022-05-05 04:26:32,065 - INFO -   File "/home/ubuntu/anaconda3/envs/dl4h-project/lib/python3.7/site-packages/trixi/experiment/experiment.py", line 89, in run
    self.train(epoch=self._epoch_idx)

  File "/home/ubuntu/DL4H-Project/TPC-LoS-prediction/models/experiment_template.py", line 155, in train
    y_hat_los, y_hat_mort = self.model(padded, diagnoses, flat)

  File "/home/ubuntu/anaconda3/envs/dl4h-project/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)

  File "/home/ubuntu/DL4H-Project/TPC-LoS-prediction/models/tpc_model2.py", line 721, in forward
    return self.forward_tpc(X=X, diagnoses=diagnoses, flat=flat, time_before_pred=time_before_pred)

  File "/home/ubuntu/DL4H-Project/TPC-LoS-prediction/models/tpc_model2.py", line 766, in forward_tpc
    **kwargs)

  File "/home/ubuntu/DL4H-Project/TPC-LoS-prediction/models/tpc_model2.py", line 473, in temp_pointwise
    X_combined = self.relu(cat((temp_skip, X_point_rep), dim=1))  # B * (F + Zt) * (1 + temp_kernels) * T

2022-05-05 04:26:32,065 - INFO - RuntimeError('CUDA out of memory. Tried to allocate 234.00 MiB (GPU 0; 14.56 GiB total capacity; 6.16 GiB already allocated; 74.50 MiB free; 6.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')
