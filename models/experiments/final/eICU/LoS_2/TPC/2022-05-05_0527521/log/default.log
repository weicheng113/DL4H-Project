2022-05-05 05:27:52,205 - INFO - Config:
2022-05-05 05:27:52,206 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/final/eICU/LoS_2/TPC",
    "batch_norm": "mybatchnorm",
    "batch_size": 24,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "TPC",
    "intermediate_reporting": false,
    "kernel_size": 4,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00226,
    "loss": "msle",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 15,
    "n_layers": 9,
    "name": "TPC",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "no_skip_connections": false,
    "no_temp_kernels": 12,
    "percentage_data": 100.0,
    "point_size": 13,
    "point_sizes": [
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13
    ],
    "save_results_csv": false,
    "seed": 1771898931,
    "share_weights": false,
    "shuffle_train": true,
    "sum_losses": true,
    "task": "LoS",
    "temp_dropout_rate": 0.05,
    "temp_kernels": [
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12
    ]
}
2022-05-05 05:27:58,213 - INFO - Experiment set up.
2022-05-05 05:28:01,696 - INFO - TempPointConv2(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (main_dropout): Dropout(p=0.45, inplace=False)
  (temp_dropout): Dropout(p=0.05, inplace=False)
  (empty_module): EmptyModule()
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
  (layer_modules): ModuleDict(
    (0): ModuleDict(
      (temp): Conv1d(174, 1044, kernel_size=(4,), stride=(1,), groups=87)
      (bn_temp): MyBatchNorm1d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=241, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ModuleDict(
      (temp): Conv1d(1400, 1200, kernel_size=(4,), stride=(1,), dilation=(3,), groups=100)
      (bn_temp): MyBatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1298, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ModuleDict(
      (temp): Conv1d(1582, 1356, kernel_size=(4,), stride=(1,), dilation=(6,), groups=113)
      (bn_temp): MyBatchNorm1d(1356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1454, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ModuleDict(
      (temp): Conv1d(1764, 1512, kernel_size=(4,), stride=(1,), dilation=(9,), groups=126)
      (bn_temp): MyBatchNorm1d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1610, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ModuleDict(
      (temp): Conv1d(1946, 1668, kernel_size=(4,), stride=(1,), dilation=(12,), groups=139)
      (bn_temp): MyBatchNorm1d(1668, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1766, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): ModuleDict(
      (temp): Conv1d(2128, 1824, kernel_size=(4,), stride=(1,), dilation=(15,), groups=152)
      (bn_temp): MyBatchNorm1d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1922, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): ModuleDict(
      (temp): Conv1d(2310, 1980, kernel_size=(4,), stride=(1,), dilation=(18,), groups=165)
      (bn_temp): MyBatchNorm1d(1980, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2078, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): ModuleDict(
      (temp): Conv1d(2492, 2136, kernel_size=(4,), stride=(1,), dilation=(21,), groups=178)
      (bn_temp): MyBatchNorm1d(2136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2234, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): ModuleDict(
      (temp): Conv1d(2674, 2292, kernel_size=(4,), stride=(1,), dilation=(24,), groups=191)
      (bn_temp): MyBatchNorm1d(2292, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2390, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (point_last_los): Linear(in_features=2985, out_features=17, bias=True)
  (point_last_mort): Linear(in_features=2985, out_features=17, bias=True)
)
2022-05-05 05:28:01,698 - INFO - number of parameters: 1151428
2022-05-05 05:28:01,698 - INFO - Experiment started at 22-05-05_05:28:01.
2022-05-05 05:41:17,323 - INFO - Train Metrics:
2022-05-05 05:41:17,325 - INFO - ==> Length of Stay:
2022-05-05 05:41:49,806 - INFO - Custom bins confusion matrix:
2022-05-05 05:41:49,806 - INFO - [[1325978  591957  112741   37657   15398    7547    4087    2379    4218
      939]
 [ 409853  549154  160560   59285   25745   13193    7010    4160    7722
     1679]
 [ 118587  312797  170550   74545   34684   18088   10286    6275   11445
     2666]
 [  44294  153732  134412   73975   38910   21396   12843    7916   14895
     3609]
 [  21319   82230   89813   61923   37024   22192   13802    8768   17678
     4487]
 [  12159   48872   60824   47706   31458   20444   13275    8805   19041
     5447]
 [   7129   32329   42881   36062   25744   17965   11877    8436   18888
     6105]
 [   4355   22164   31280   27828   20621   14955   10518    7620   18097
     6279]
 [  10521   56478   82696   79699   64528   50077   37565   28841   76871
    34503]
 [   5510   30658   46870   47476   40299   31836   25731   19767   57540
    31141]]
2022-05-05 05:41:57,041 - INFO - Mean absolute deviation (MAD) = 2.4687177232759336
2022-05-05 05:41:57,041 - INFO - Mean squared error (MSE) = 32.367111038034345
2022-05-05 05:41:57,041 - INFO - Mean absolute percentage error (MAPE) = 104.35026977939674
2022-05-05 05:41:57,041 - INFO - Mean squared logarithmic error (MSLE) = 1.2004039176968693
2022-05-05 05:41:57,041 - INFO - R^2 Score = 0.11722288484393606
2022-05-05 05:41:57,041 - INFO - Cohen kappa score = 0.4460949849260831
2022-05-05 05:41:57,790 - INFO - Epoch: 0 | Train Loss: 75.5238
2022-05-05 05:43:42,621 - INFO - Validation Metrics:
2022-05-05 05:43:42,621 - INFO - ==> Length of Stay:
2022-05-05 05:43:49,456 - INFO - Custom bins confusion matrix:
2022-05-05 05:43:49,457 - INFO - [[330248  92788  16805   6102   2267    862    368    101     63      0]
 [ 81819 134171  28857  10881   4303   1737    773    314    141      0]
 [ 12081  76548  41580  17270   7779   3449   1521    675    312      0]
 [  3272  27355  32578  22031  10967   5743   2705   1225    766      1]
 [  1192   9882  17749  19079  13024   7210   3718   1935   1602      7]
 [   680   4446   9297  13388  11904   8122   4426   2241   2472     28]
 [   455   2441   4731   8223   8934   7295   4973   2916   3325     37]
 [   275   1601   3140   5162   6447   5678   4733   3188   4289     54]
 [   699   3692   6898  10536  13679  16122  16230  13696  28231   1237]
 [   513   1917   2912   4614   6240   7935   9077   9263  27603   1607]]
2022-05-05 05:43:50,898 - INFO - Mean absolute deviation (MAD) = 1.9853037692176507
2022-05-05 05:43:50,898 - INFO - Mean squared error (MSE) = 49.78635306214381
2022-05-05 05:43:50,898 - INFO - Mean absolute percentage error (MAPE) = 75.65179111563012
2022-05-05 05:43:50,898 - INFO - Mean squared logarithmic error (MSLE) = 0.7966438235215434
2022-05-05 05:43:50,898 - INFO - R^2 Score = 0.1935606626680284
2022-05-05 05:43:50,898 - INFO - Cohen kappa score = 0.6083423794687832
2022-05-05 05:43:51,460 - INFO - Epoch: 0 | Validation Loss: 49.6983
2022-05-05 05:43:51,462 - INFO - Done epoch 0, spent 0:15:49.765008.
2022-05-05 05:44:14,732 - INFO - Experiment exited. Checkpoints stored =)
