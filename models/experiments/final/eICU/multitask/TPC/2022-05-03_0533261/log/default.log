2022-05-03 05:33:26,762 - INFO - Config:
2022-05-03 05:33:26,762 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/final/eICU/multitask/TPC",
    "batch_norm": "mybatchnorm",
    "batch_size": 48,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "TPC",
    "intermediate_reporting": false,
    "kernel_size": 4,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00226,
    "loss": "msle",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 15,
    "n_layers": 9,
    "name": "TPC",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "no_skip_connections": false,
    "no_temp_kernels": 12,
    "percentage_data": 100.0,
    "point_size": 13,
    "point_sizes": [
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13
    ],
    "save_results_csv": false,
    "seed": 2394505222,
    "share_weights": false,
    "shuffle_train": true,
    "sum_losses": true,
    "task": "multitask",
    "temp_dropout_rate": 0.05,
    "temp_kernels": [
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12
    ]
}
2022-05-03 05:33:31,290 - INFO - Experiment set up.
2022-05-03 05:33:34,666 - INFO - TempPointConv(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (main_dropout): Dropout(p=0.45, inplace=False)
  (temp_dropout): Dropout(p=0.05, inplace=False)
  (empty_module): EmptyModule()
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
  (layer_modules): ModuleDict(
    (0): ModuleDict(
      (temp): Conv1d(174, 1044, kernel_size=(4,), stride=(1,), groups=87)
      (bn_temp): MyBatchNorm1d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=241, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ModuleDict(
      (temp): Conv1d(1300, 1200, kernel_size=(4,), stride=(1,), dilation=(3,), groups=100)
      (bn_temp): MyBatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1298, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ModuleDict(
      (temp): Conv1d(1469, 1356, kernel_size=(4,), stride=(1,), dilation=(6,), groups=113)
      (bn_temp): MyBatchNorm1d(1356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1454, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ModuleDict(
      (temp): Conv1d(1638, 1512, kernel_size=(4,), stride=(1,), dilation=(9,), groups=126)
      (bn_temp): MyBatchNorm1d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1610, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ModuleDict(
      (temp): Conv1d(1807, 1668, kernel_size=(4,), stride=(1,), dilation=(12,), groups=139)
      (bn_temp): MyBatchNorm1d(1668, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1766, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): ModuleDict(
      (temp): Conv1d(1976, 1824, kernel_size=(4,), stride=(1,), dilation=(15,), groups=152)
      (bn_temp): MyBatchNorm1d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1922, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): ModuleDict(
      (temp): Conv1d(2145, 1980, kernel_size=(4,), stride=(1,), dilation=(18,), groups=165)
      (bn_temp): MyBatchNorm1d(1980, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2078, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): ModuleDict(
      (temp): Conv1d(2314, 2136, kernel_size=(4,), stride=(1,), dilation=(21,), groups=178)
      (bn_temp): MyBatchNorm1d(2136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2234, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): ModuleDict(
      (temp): Conv1d(2483, 2292, kernel_size=(4,), stride=(1,), dilation=(24,), groups=191)
      (bn_temp): MyBatchNorm1d(2292, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2390, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (point_last_los): Linear(in_features=2781, out_features=17, bias=True)
  (point_last_mort): Linear(in_features=2781, out_features=17, bias=True)
)
2022-05-03 05:33:34,668 - INFO - Experiment started at 22-05-03_05:33:34.
2022-05-03 05:47:24,859 - INFO - Train Metrics:
2022-05-03 05:47:56,127 - INFO - Custom bins confusion matrix:
2022-05-03 05:47:56,128 - INFO - [[1056295  789646  157737   52112   21359   10427    5389    3082    5280
     1171]
 [ 387023  536274  175375   70451   31045   15380    8190    4924    8008
     1612]
 [ 152221  314927  146852   67932   33250   17296    9669    5741   10056
     1945]
 [  67431  186838  114106   59853   31207   17288    9888    6185   10962
     2217]
 [  34431  116694   85601   49997   27744   16060    9559    5902   10914
     2331]
 [  20270   76365   64227   41088   24085   14412    8887    5535   10653
     2518]
 [  12433   53005   49184   33778   20804   12652    7873    5121   10031
     2559]
 [   7494   38107   38581   27575   17501   11107    7039    4511    9378
     2448]
 [  17332  101010  115566   89950   61330   40327   26846   18420   39278
    11767]
 [   7653   50467   66205   58257   42801   30140   20890   14973   34075
    11367]]
2022-05-03 05:48:04,241 - INFO - Confusion matrix:
2022-05-03 05:48:04,241 - INFO - [[59634   578]
 [ 6298   396]]
2022-05-03 05:48:04,931 - INFO - Epoch: 0 | Train Loss: 103.7194
2022-05-03 05:49:46,234 - INFO - Validation Metrics:
2022-05-03 05:49:53,038 - INFO - Custom bins confusion matrix:
2022-05-03 05:49:53,038 - INFO - [[270197 138299  27068   8940   2969   1240    654    191     46      0]
 [ 68347 122461  42854  18188   6998   2546   1080    355    167      0]
 [ 13979  64286  41243  23078  11324   4449   1811    665    380      0]
 [  4454  29099  29273  21030  12177   6275   2594   1023    704     14]
 [  1636  14626  18419  17458  10845   6542   3212   1582   1052     26]
 [  1060   8186  11863  13328   9825   6049   3340   1802   1527     24]
 [   659   4636   7437   9612   8420   5610   3325   1904   1711     16]
 [   427   3318   4702   6884   6840   5350   3390   1753   1893     10]
 [  1016   6946  11248  17062  20082  18795  15065  10080  10479    247]
 [   432   3146   4906   8497  11133  12823  11945   8083  10440    276]]
2022-05-03 05:49:54,959 - INFO - Confusion matrix:
2022-05-03 05:49:54,959 - INFO - [[12950     3]
 [ 1302    45]]
2022-05-03 05:49:55,718 - INFO - Epoch: 0 | Validation Loss: 70.7626
2022-05-03 05:49:55,720 - INFO - Done epoch 0, spent 0:16:21.052373.
2022-05-03 05:50:19,690 - INFO - Experiment exited. Checkpoints stored =)
